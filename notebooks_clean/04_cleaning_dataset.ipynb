{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "053f16e3",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Purpose\n",
    "This notebook performs data quality checks and cleaning on the combined life expectancy dataset. Since we used **inner join** in notebook 03, most data quality issues should already be filtered out. This notebook focuses on:\n",
    "\n",
    "1. Identifying and handling missing values (NaN/empty fields)\n",
    "2. Detecting and removing Census API error codes (`-666666666`)\n",
    "3. Verifying data integrity and consistency\n",
    "4. Saving the cleaned dataset for feature engineering\n",
    "\n",
    "## Input\n",
    "- `data_cleaned/processed/combined_by_year/combined_all_years.csv`\n",
    "- Expected: County-year observations with 19 ACS variables\n",
    "- Years: 2012-2019\n",
    "\n",
    "## Output\n",
    "- `data_cleaned/combined_all_years_cleaned.csv`\n",
    "- Clean dataset ready for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74988803",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefebdd",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Read the combined dataset from notebook 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined dataset\n",
    "df = pd.read_csv('../data_cleaned/processed/combined_by_year/combined_all_years.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"  - Rows (county-year observations): {df.shape[0]:,}\")\n",
    "print(f\"  - Columns (features + identifiers): {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82012564",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection\n",
    "\n",
    "Review the structure, data types, and first few rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "print(\"Dataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2129864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all column names\n",
    "print(f\"Total columns: {len(df.columns)}\\n\")\n",
    "print(\"Column names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c848f",
   "metadata": {},
   "source": [
    "## 4. Check for Missing Values\n",
    "\n",
    "Identify any missing values (NaN or empty fields) in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da78fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values per column\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "print(\"=\" * 60)\n",
    "for col in df.columns:\n",
    "    if missing_values[col] > 0:\n",
    "        pct = (missing_values[col] / len(df)) * 100\n",
    "        print(f\"{col:40s}: {missing_values[col]:5} ({pct:.2f}%)\")\n",
    "\n",
    "total_missing = missing_values.sum()\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total missing values: {total_missing}\")\n",
    "\n",
    "if total_missing == 0:\n",
    "    print(\"\\n✓ No missing values detected!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5627bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are missing values, examine the affected rows\n",
    "if df.isnull().any().any():\n",
    "    print(\"\\nRows with missing values:\")\n",
    "    print(\"=\" * 60)\n",
    "    rows_with_missing = df[df.isnull().any(axis=1)]\n",
    "    print(f\"Total rows affected: {len(rows_with_missing)}\")\n",
    "    print(\"\\nSample of affected rows:\")\n",
    "    print(rows_with_missing.head(10))\n",
    "else:\n",
    "    print(\"\\n✓ No rows with missing values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642490f7",
   "metadata": {},
   "source": [
    "## 5. Check for Census Error Codes\n",
    "\n",
    "The Census API uses `-666666666` to indicate \"data not available\" or other data quality issues. Identify any occurrences of this error code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42090d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for -666666666 error codes\n",
    "error_code_mask = (df == -666666666).any(axis=1)\n",
    "rows_with_errors = df[error_code_mask]\n",
    "\n",
    "print(\"Census API Error Code Check:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Rows with -666666666 error codes: {len(rows_with_errors)}\")\n",
    "\n",
    "if len(rows_with_errors) > 0:\n",
    "    print(f\"Percentage of dataset: {(len(rows_with_errors) / len(df)) * 100:.2f}%\")\n",
    "    print(\"\\nColumns affected:\")\n",
    "    for col in df.columns:\n",
    "        count = (df[col] == -666666666).sum()\n",
    "        if count > 0:\n",
    "            print(f\"  {col}: {count} occurrences\")\n",
    "    \n",
    "    print(\"\\nSample of affected rows:\")\n",
    "    print(rows_with_errors.head(10))\n",
    "else:\n",
    "    print(\"✓ No Census error codes found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182edcb",
   "metadata": {},
   "source": [
    "## 6. Remove Problematic Rows\n",
    "\n",
    "Remove all rows that contain either missing values or Census error codes. Since we used inner join, these should be minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5c076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cleaned dataset by removing problematic rows\n",
    "print(\"Cleaning dataset...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Starting size\n",
    "print(f\"Original dataset: {len(df):,} rows\")\n",
    "\n",
    "# Step 1: Remove rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(f\"After removing missing values: {len(df_cleaned):,} rows ({len(df) - len(df_cleaned)} removed)\")\n",
    "\n",
    "# Step 2: Remove rows with Census error codes\n",
    "df_cleaned = df_cleaned[(df_cleaned != -666666666).all(axis=1)]\n",
    "print(f\"After removing error codes: {len(df_cleaned):,} rows ({len(df) - len(df_cleaned)} total removed)\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"Final cleaned dataset: {len(df_cleaned):,} rows\")\n",
    "print(f\"Rows removed: {len(df) - len(df_cleaned)} ({((len(df) - len(df_cleaned)) / len(df)) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfcf087",
   "metadata": {},
   "source": [
    "## 7. Verify Cleaned Dataset\n",
    "\n",
    "Perform final checks to ensure the cleaned dataset has no remaining issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification checks\n",
    "print(\"Cleaned Dataset Verification:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check for missing values\n",
    "missing_after = df_cleaned.isnull().sum().sum()\n",
    "print(f\"Missing values: {missing_after}\")\n",
    "\n",
    "# Check for error codes\n",
    "error_codes_after = (df_cleaned == -666666666).any().any()\n",
    "print(f\"Error codes remaining: {error_codes_after}\")\n",
    "\n",
    "# Check data integrity\n",
    "print(f\"\\nShape: {df_cleaned.shape}\")\n",
    "print(f\"Years present: {sorted(df_cleaned['Year'].unique())}\")\n",
    "print(f\"Counties per year:\")\n",
    "print(df_cleaned.groupby('Year').size())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if missing_after == 0 and not error_codes_after:\n",
    "    print(\"✓ Dataset is clean and ready for feature engineering!\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Issues remain in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f1ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the target variable\n",
    "print(\"\\nSummary Statistics for Life Expectancy:\")\n",
    "print(\"=\" * 60)\n",
    "print(df_cleaned['mean_life_expectancy'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a69c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of cleaned dataset\n",
    "print(\"Sample of cleaned dataset:\")\n",
    "df_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d2796",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering: Race Percentages\n",
    "\n",
    "Calculate race percentages from population counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaa07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating race percentages...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# White Population (%)\n",
    "df_cleaned['White Population (%)'] = (df_cleaned['White Population'] / df_cleaned['Total Population']) * 100\n",
    "\n",
    "# Hispanic Population (%)\n",
    "df_cleaned['Hispanic Population (%)'] = (df_cleaned['Hispanic Population'] / df_cleaned['Total Population']) * 100\n",
    "\n",
    "# Black Population (%)\n",
    "df_cleaned['Black Population (%)'] = (df_cleaned['Black Population'] / df_cleaned['Total Population']) * 100\n",
    "\n",
    "print(\"✓ Race percentages calculated\")\n",
    "print(\"\\nNew columns created:\")\n",
    "print(\"  - White Population (%)\")\n",
    "print(\"  - Hispanic Population (%)\")\n",
    "print(\"  - Black Population (%)\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(\"\\nWhite Population (%):\")\n",
    "print(df_cleaned['White Population (%)'].describe())\n",
    "print(\"\\nHispanic Population (%):\")\n",
    "print(df_cleaned['Hispanic Population (%)'].describe())\n",
    "print(\"\\nBlack Population (%):\")\n",
    "print(df_cleaned['Black Population (%)'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7629e71d",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering: Housing and Family Percentages\n",
    "\n",
    "Calculate percentages for housing and family characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating housing and family percentages...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Households with No Vehicle (%)\n",
    "df_cleaned['Households with No Vehicle (%)'] = (\n",
    "    (df_cleaned['No Vehicle (Owner)'] + df_cleaned['No Vehicle (Renter)']) / \n",
    "    df_cleaned['Total Occupied Households']\n",
    ") * 100\n",
    "\n",
    "# Rent Burden (+50% of HI)\n",
    "df_cleaned['Rent Burden (+50% of HI)'] = (\n",
    "    df_cleaned['Rent Burden Count (+50%)'] / \n",
    "    df_cleaned['Rent Denominator']\n",
    ") * 100\n",
    "\n",
    "# Single Mother Families (%)\n",
    "df_cleaned['Single Mother Families (%)'] = (\n",
    "    df_cleaned['Total Families (Single Mother)'] / \n",
    "    df_cleaned['Total Families']\n",
    ") * 100\n",
    "\n",
    "print(\"✓ Housing and family percentages calculated\")\n",
    "print(\"\\nNew columns created:\")\n",
    "print(\"  - Households with No Vehicle (%)\")\n",
    "print(\"  - Rent Burden (+50% of HI)\")\n",
    "print(\"  - Single Mother Families (%)\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(\"\\nHouseholds with No Vehicle (%):\")\n",
    "print(df_cleaned['Households with No Vehicle (%)'].describe())\n",
    "print(\"\\nRent Burden (+50% of HI):\")\n",
    "print(df_cleaned['Rent Burden (+50% of HI)'].describe())\n",
    "print(\"\\nSingle Mother Families (%):\")\n",
    "print(df_cleaned['Single Mother Families (%)'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97272490",
   "metadata": {},
   "source": [
    "## 10. Drop Raw Count Columns\n",
    "\n",
    "Remove the raw count columns that were used to create percentages, keeping only Total Population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c653372",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dropping raw count columns...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Columns to drop (all used for percentage calculations except Total Population)\n",
    "columns_to_drop = [\n",
    "    'White Population',\n",
    "    'Hispanic Population',\n",
    "    'Black Population',\n",
    "    'No Vehicle (Owner)',\n",
    "    'No Vehicle (Renter)',\n",
    "    'Total Occupied Households',\n",
    "    'Rent Burden Count (+50%)',\n",
    "    'Rent Denominator',\n",
    "    'Total Families (Single Mother)',\n",
    "    'Total Families'\n",
    "]\n",
    "\n",
    "df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"✓ Dropped {len(columns_to_drop)} columns\")\n",
    "print(\"\\nColumns dropped:\")\n",
    "for col in columns_to_drop:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(f\"\\nDataset shape after dropping: {df_cleaned.shape}\")\n",
    "print(f\"  - Rows: {df_cleaned.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df_cleaned.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14681fb",
   "metadata": {},
   "source": [
    "## 11. Rename Target Variable\n",
    "\n",
    "Rename the target variable for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Renaming target variable...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Rename mean_life_expectancy to Mean Life Expectancy\n",
    "df_cleaned = df_cleaned.rename(columns={'mean_life_expectancy': 'Mean Life Expectancy'})\n",
    "\n",
    "print(\"✓ Renamed 'mean_life_expectancy' to 'Mean Life Expectancy'\")\n",
    "print(f\"\\nTarget variable summary:\")\n",
    "print(df_cleaned['Mean Life Expectancy'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c8ba7",
   "metadata": {},
   "source": [
    "## 12. Final Dataset Verification\n",
    "\n",
    "Review the final dataset structure with all engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Dataset Structure:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Shape: {df_cleaned.shape}\")\n",
    "print(f\"  - Rows: {df_cleaned.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df_cleaned.shape[1]}\")\n",
    "\n",
    "print(\"\\nAll column names:\")\n",
    "for i, col in enumerate(df_cleaned.columns, 1):\n",
    "    print(f\"{i:2}. {col}\")\n",
    "\n",
    "print(\"\\nSample of final dataset:\")\n",
    "df_cleaned.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13215697",
   "metadata": {},
   "source": [
    "## 13. Save Final Dataset\n",
    "\n",
    "Export the cleaned and engineered dataset for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae889cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = Path('../data_cleaned/demographics_final')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save final cleaned and engineered dataset\n",
    "output_path = output_dir / 'combined_all_years_cleaned_final.csv'\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET SAVED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"✓ Final dataset saved to: {output_path}\")\n",
    "print(f\"\\n  - Shape: {df_cleaned.shape}\")\n",
    "print(f\"  - Rows: {df_cleaned.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df_cleaned.shape[1]}\")\n",
    "print(f\"  - File size: {output_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "print(f\"\\n  - Engineered features: 6\")\n",
    "print(f\"  - Ready for machine learning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa02324",
   "metadata": {},
   "source": [
    "## 14. Summary\n",
    "\n",
    "**Data Cleaning Results:**\n",
    "- Original observations: See output in Section 6\n",
    "- Rows removed: See output in Section 6\n",
    "- Final clean observations: See output in Section 6\n",
    "\n",
    "**Quality Checks Passed:**\n",
    "- ✓ No missing values (NaN)\n",
    "- ✓ No Census error codes (-666666666)\n",
    "- ✓ All years present (2012-2019)\n",
    "- ✓ Consistent county counts across years\n",
    "\n",
    "**Feature Engineering Completed:**\n",
    "- **Race Percentages (3 features):**\n",
    "  - White Population (%) = (White Population / Total Population) × 100\n",
    "  - Hispanic Population (%) = (Hispanic Population / Total Population) × 100\n",
    "  - Black Population (%) = (Black Population / Total Population) × 100\n",
    "\n",
    "- **Housing & Family Percentages (3 features):**\n",
    "  - Households with No Vehicle (%) = [(No Vehicle Owner + Renter) / Total Households] × 100\n",
    "  - Rent Burden (+50% of HI) = (Rent Burden Count / Rent Denominator) × 100\n",
    "  - Single Mother Families (%) = (Single Mother Families / Total Families) × 100\n",
    "\n",
    "**Columns Dropped:**\n",
    "- Raw count columns used for percentages (10 columns dropped)\n",
    "- Kept: Total Population (useful as a feature)\n",
    "\n",
    "**Target Variable:**\n",
    "- Renamed `mean_life_expectancy` → `Mean Life Expectancy`\n",
    "\n",
    "**Final Dataset:**\n",
    "- **Location:** `data_cleaned/demographics_final/combined_all_years_cleaned_final.csv`\n",
    "- **Features:** 19 variables (6 engineered + 13 original) + identifiers + target\n",
    "- **Ready for:** Exploratory Data Analysis (EDA) and Machine Learning models\n",
    "\n",
    "**Next Steps:**\n",
    "- Proceed to notebook 05 for EDA and additional analysis\n",
    "- Then notebooks 06+ for machine learning model development"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
