{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6313bbd1",
   "metadata": {},
   "source": [
    "# Create Final Reduced Dataset\n",
    "\n",
    "## Purpose\n",
    "This notebook creates the final reduced dataset by:\n",
    "1. **Dropping redundant demographics variables** (6 variables identified in notebook 06)\n",
    "2. **Dropping irrelevant weather variables** (67 variables from notebook 07)\n",
    "3. **Dropping redundant weather variables** (15 variables from correlation analysis in notebook 07)\n",
    "4. **Formatting weather variable names** to Title Case for publication\n",
    "5. **Verifying data quality** and final feature set\n",
    "6. **Saving final reduced dataset** ready for modeling\n",
    "\n",
    "## Input\n",
    "- `data_cleaned/combined_final/final_combined_all_variables.csv` (from notebook 05)\n",
    "\n",
    "## Output\n",
    "- `data_cleaned/combined_final/final_combined_all_variables_reduced.csv`\n",
    "- Publication-ready dataset with selected features only\n",
    "\n",
    "## Expected Changes\n",
    "- **Demographics**: 15 → 9 variables (drop 6)\n",
    "- **Weather**: ~103 → ~21 variables (drop 82)\n",
    "- **Livestock**: 8 variables (keep all)\n",
    "- **Total**: ~138 → ~42 variables (drop 88)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a8a28",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4194de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "pandas version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600f43c",
   "metadata": {},
   "source": [
    "## 2. Load Combined Dataset\n",
    "\n",
    "Load the full combined dataset from notebook 05 (before any feature reduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb0ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ORIGINAL DATASET LOADED\n",
      "======================================================================\n",
      "Shape: (24487, 131)\n",
      "  - Rows: 24,487\n",
      "  - Columns: 131\n",
      "  - Years: [2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n"
     ]
    }
   ],
   "source": [
    "# Load combined dataset\n",
    "df = pd.read_csv('../data_cleaned/combined_final/final_combined_all_variables.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ORIGINAL DATASET LOADED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"  - Rows: {df.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df.shape[1]}\")\n",
    "print(f\"  - Years: {sorted(df['Year'].unique())}\")\n",
    "\n",
    "# Store original shape for comparison\n",
    "original_rows = df.shape[0]\n",
    "original_cols = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3c442",
   "metadata": {},
   "source": [
    "## 3. Define Variables to Drop\n",
    "\n",
    "### 3.1 Redundant Demographics Variables\n",
    "\n",
    "Based on correlation analysis in notebook 06, drop 6 demographics variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f57bb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics variables to drop:\n",
      "  Total: 6\n",
      "    1. Rent Burden (+50% of HI)\n",
      "    2. Median Household Income\n",
      "    3. Gini Index\n",
      "    4. White Population (%)\n",
      "    5. High School Degree or Higher (%)\n",
      "    6. Median Age\n"
     ]
    }
   ],
   "source": [
    "# Demographics variables to drop (from notebook 06 analysis)\n",
    "demographics_to_drop = [\n",
    "    'Rent Burden (+50% of HI)',\n",
    "    'Median Household Income',\n",
    "    'Gini Index',\n",
    "    'White Population (%)',\n",
    "    'High School Degree or Higher (%)',\n",
    "    'Median Age'\n",
    "]\n",
    "\n",
    "print(\"Demographics variables to drop:\")\n",
    "print(f\"  Total: {len(demographics_to_drop)}\")\n",
    "for i, var in enumerate(demographics_to_drop, 1):\n",
    "    print(f\"    {i}. {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039a23f",
   "metadata": {},
   "source": [
    "### 3.2 Irrelevant Weather Variables\n",
    "\n",
    "These 67 weather variables are known to be redundant or irrelevant (from notebook 07 step 4.3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e462bf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irrelevant weather variables to drop: 59\n"
     ]
    }
   ],
   "source": [
    "# Irrelevant weather variables (from notebook 07 step 4.3)\n",
    "irrelevant_weather = [\n",
    "    'PM$_{10}$',\n",
    "    'FoT PM$_{10}$ above EPA threshold', \n",
    "    'FoT PM$_{10}$ above75ᵗʰ percentile',\n",
    "    'FoT PM$_{1}$ above75ᵗʰ percentile', \n",
    "    'PM$_1$', \n",
    "    'Specific humidity.1', \n",
    "    'Total column water',\n",
    "    '2m dew point temperature', \n",
    "    'Wet bulb temperature', \n",
    "    '2m temperature',\n",
    "    'PM$_{2.5}$', \n",
    "    'FoT Temperature above 90 $\\\\mathrm{^o F}$', \n",
    "    'FoT Temperature below 0 $\\\\mathrm{^o C}$',\n",
    "    'FoT PM$_{2.5}$ above EPA threshold', \n",
    "    'Temperature', \n",
    "    'Surface geopotential',\n",
    "    'Dust aerosol (0.03-0.55 µm) mixing ratio', \n",
    "    'Nitrogen dioxide', \n",
    "    'Peroxyacetyl nitrate', \n",
    "    'Formaldehyde',\n",
    "    'Sulphur dioxide', \n",
    "    'Nitric acid', \n",
    "    'Propane',\n",
    "    'Nitrogen monoxide',\n",
    "    'Ozone', \n",
    "    'Hydrogen peroxide', \n",
    "    'Specific humidity',\n",
    "    \n",
    "    # Total AOD measurements (redundant aerosol measurements)\n",
    "    'Total AOD at 469 nm', \n",
    "    'Total AOD at 550 nm', \n",
    "    'Total AOD at 670 nm', \n",
    "    'Total AOD at 865 nm',\n",
    "    'Total AOD at 1240 nm',\n",
    "    \n",
    "    # Total column gas measurements (redundant with other air quality measures)\n",
    "    'Total column carbon monoxide', \n",
    "    'Total column ethane', \n",
    "    'Total column formaldehyde',\n",
    "    'Total column hydrogen peroxide', \n",
    "    'Total column hydroxyl radical', \n",
    "    'Total column isoprene', \n",
    "    'Total column methane', \n",
    "    'Total column nitric acid', \n",
    "    'Total column nitrogen dioxide', \n",
    "    'Total column ozone', \n",
    "    'Total column peroxyacetyl nitrate',\n",
    "    'Total column propane', \n",
    "    'Total column sulphur dioxide', \n",
    "    'Total column water vapour',\n",
    "    'Total column nitrogen monoxide',\n",
    "    \n",
    "    # Vertically integrated aerosol masses (redundant)\n",
    "    'Vertically integrated mass of dust aerosol (0.03-0.55 µm)',\n",
    "    'Vertically integrated mass of dust aerosol (0.55-9 µm)', \n",
    "    'Vertically integrated mass of dust aerosol (9-20 µm)',\n",
    "    'Vertically integrated mass of hydrophilic black carbon aerosol', \n",
    "    'Vertically integrated mass of hydrophilic organic matter aerosol',\n",
    "    'Vertically integrated mass of hydrophobic organic matter aerosol',\n",
    "    'Vertically integrated mass of hydrophobic black carbon aerosol', \n",
    "    'Vertically integrated mass of sea salt aerosol (0.03-0.5 µm)',\n",
    "    'Vertically integrated mass of sea salt aerosol (0.5-5 µm)', \n",
    "    'Vertically integrated mass of sea salt aerosol (5-20 µm)',\n",
    "    'Vertically integrated mass of sulphate aerosol', \n",
    "    'Vertically integrated mass of sulphur dioxide'\n",
    "]\n",
    "\n",
    "print(f\"Irrelevant weather variables to drop: {len(irrelevant_weather)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acf940",
   "metadata": {},
   "source": [
    "### 3.3 Redundant Weather Variables from Analysis\n",
    "\n",
    "These 15 weather variables were identified as redundant in notebook 07 correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "581e93b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundant weather variables to drop (from analysis):\n",
      "  Total: 15\n",
      "     1. Dust aerosol (0.9-20 µm) mixing ratio\n",
      "     2. Hydrophobic black carbon aerosol mixing ratio\n",
      "     3. Sea salt aerosol (5-20 µm) mixing ratio\n",
      "     4. Dust aerosol (0.55-0.9 µm) mixing ratio\n",
      "     5. Sea salt aerosol (0.5-5 µm) mixing ratio\n",
      "     6. Hydrophilic black carbon aerosol mixing ratio\n",
      "     7. Sulphate aerosol mixing ratio\n",
      "     8. Hydroxyl radical\n",
      "     9. FoT Temperature below25ᵗʰ percentile\n",
      "    10. FoT Temperature above75ᵗʰ percentile\n",
      "    11. Sea salt aerosol (0.03-0.5 µm) mixing ratio\n",
      "    12. Hydrophobic organic matter aerosol mixing ratio\n",
      "    13. Carbon monoxide\n",
      "    14. Ethane\n",
      "    15. Hydrophilic organic matter aerosol mixing ratio\n"
     ]
    }
   ],
   "source": [
    "# Redundant weather variables (from notebook 07 correlation analysis)\n",
    "redundant_weather = [\n",
    "    'Dust aerosol (0.9-20 µm) mixing ratio',\n",
    "    'Hydrophobic black carbon aerosol mixing ratio',\n",
    "    'Sea salt aerosol (5-20 µm) mixing ratio',\n",
    "    'Dust aerosol (0.55-0.9 µm) mixing ratio',\n",
    "    'Sea salt aerosol (0.5-5 µm) mixing ratio',\n",
    "    'Hydrophilic black carbon aerosol mixing ratio',\n",
    "    'Sulphate aerosol mixing ratio',\n",
    "    'Hydroxyl radical',\n",
    "    'FoT Temperature below25ᵗʰ percentile',\n",
    "    'FoT Temperature above75ᵗʰ percentile',\n",
    "    'Sea salt aerosol (0.03-0.5 µm) mixing ratio',\n",
    "    'Hydrophobic organic matter aerosol mixing ratio',\n",
    "    'Carbon monoxide',\n",
    "    'Ethane',\n",
    "    'Hydrophilic organic matter aerosol mixing ratio'\n",
    "]\n",
    "\n",
    "print(\"Redundant weather variables to drop (from analysis):\")\n",
    "print(f\"  Total: {len(redundant_weather)}\")\n",
    "for i, var in enumerate(redundant_weather, 1):\n",
    "    print(f\"    {i:2}. {var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a933b",
   "metadata": {},
   "source": [
    "### 3.4 Combine All Variables to Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "416eb157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY: VARIABLES TO DROP\n",
      "======================================================================\n",
      "  Demographics: 6\n",
      "  Irrelevant weather: 59\n",
      "  Redundant weather: 15\n",
      "  TOTAL: 80\n"
     ]
    }
   ],
   "source": [
    "# Combine all variables to drop\n",
    "all_vars_to_drop = demographics_to_drop + irrelevant_weather + redundant_weather\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY: VARIABLES TO DROP\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Demographics: {len(demographics_to_drop)}\")\n",
    "print(f\"  Irrelevant weather: {len(irrelevant_weather)}\")\n",
    "print(f\"  Redundant weather: {len(redundant_weather)}\")\n",
    "print(f\"  TOTAL: {len(all_vars_to_drop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388f896",
   "metadata": {},
   "source": [
    "## 4. Check Which Variables Exist\n",
    "\n",
    "Filter to only drop columns that actually exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732d24f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COLUMNS TO DROP (THAT EXIST IN DATASET)\n",
      "======================================================================\n",
      "Specified: 80\n",
      "Found in dataset: 80\n",
      "Not found: 0\n",
      "\n",
      " All specified columns exist in the dataset\n"
     ]
    }
   ],
   "source": [
    "# Filter to only columns that exist in the dataset\n",
    "cols_to_drop = [col for col in all_vars_to_drop if col in df.columns]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COLUMNS TO DROP (THAT EXIST IN DATASET)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Specified: {len(all_vars_to_drop)}\")\n",
    "print(f\"Found in dataset: {len(cols_to_drop)}\")\n",
    "print(f\"Not found: {len(all_vars_to_drop) - len(cols_to_drop)}\")\n",
    "\n",
    "# Check which columns don't exist (for debugging)\n",
    "cols_not_found = [col for col in all_vars_to_drop if col not in df.columns]\n",
    "if cols_not_found:\n",
    "    print(f\"\\n Columns NOT found in dataset ({len(cols_not_found)}):\")\n",
    "    for i, col in enumerate(cols_not_found[:10], 1):\n",
    "        print(f\"    {i}. {col}\")\n",
    "    if len(cols_not_found) > 10:\n",
    "        print(f\"    ... and {len(cols_not_found) - 10} more\")\n",
    "else:\n",
    "    print(\"\\n All specified columns exist in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb79ab5",
   "metadata": {},
   "source": [
    "## 5. Drop Redundant Columns\n",
    "\n",
    "Remove all identified redundant variables from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6534308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DROPPING REDUNDANT COLUMNS\n",
      "======================================================================\n",
      "\n",
      "Original shape: (24487, 131)\n",
      "  - Rows: 24,487\n",
      "  - Columns: 131\n",
      "\n",
      "Reduced shape: (24487, 51)\n",
      "  - Rows: 24,487 (no change ✓)\n",
      "  - Columns: 51\n",
      "  - Columns dropped: 80\n",
      "  - Retention: 38.9%\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DROPPING REDUNDANT COLUMNS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nOriginal shape: {df.shape}\")\n",
    "print(f\"  - Rows: {original_rows:,}\")\n",
    "print(f\"  - Columns: {original_cols}\")\n",
    "\n",
    "# Drop columns\n",
    "df_reduced = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# New shape\n",
    "reduced_rows = df_reduced.shape[0]\n",
    "reduced_cols = df_reduced.shape[1]\n",
    "cols_dropped = original_cols - reduced_cols\n",
    "\n",
    "print(f\"\\nReduced shape: {df_reduced.shape}\")\n",
    "print(f\"  - Rows: {reduced_rows:,} (no change ✓)\")\n",
    "print(f\"  - Columns: {reduced_cols}\")\n",
    "print(f\"  - Columns dropped: {cols_dropped}\")\n",
    "print(f\"  - Retention: {(reduced_cols / original_cols) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a680bf1e",
   "metadata": {},
   "source": [
    "## 6. Identify Remaining Variables\n",
    "\n",
    "Categorize remaining columns by type for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e87325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REMAINING COLUMNS (51)\n",
      "======================================================================\n",
      "\n",
      "1. Identifiers (3):\n",
      "      County\n",
      "      State\n",
      "      Year\n",
      "\n",
      "2. Target Variable (1):\n",
      "      Mean Life Expectancy\n",
      "\n",
      "3. Demographics Variables (9):\n",
      "     1. Total Population\n",
      "     2. Poverty Rate\n",
      "     3. Unemployment Rate\n",
      "     4. Disability Rate\n",
      "     5. Bachelor's Degree or Higher (%)\n",
      "     6. Hispanic Population (%)\n",
      "     7. Black Population (%)\n",
      "     8. Households with No Vehicle (%)\n",
      "     9. Single Mother Families (%)\n",
      "\n",
      "4. Livestock Variables (8):\n",
      "     1. Buffalo\n",
      "     2. Cattle\n",
      "     3. Chicken\n",
      "     4. Duck\n",
      "     5. Goat\n",
      "     6. Horse\n",
      "     7. Pig\n",
      "     8. Sheep\n",
      "\n",
      "5. Weather Variables (30):\n",
      "      1. 10m wind speed\n",
      "      2. Black carbon AOD at 550 nm\n",
      "      3. Dust AOD at 550 nm\n",
      "      4. FoT Carbonmonoxide above75ᵗʰ percentile\n",
      "      5. FoT Ethane above75ᵗʰ percentile\n",
      "      6. FoT Formaldehyde above75ᵗʰ percentile\n",
      "      7. FoT Hydrogen peroxide above75ᵗʰ percentile\n",
      "      8. FoT Hydroxyl radical above75ᵗʰ percentile\n",
      "      9. FoT Isoprene above75ᵗʰ percentile\n",
      "     10. FoT Nitric acid above75ᵗʰ percentile\n",
      "     11. FoT Nitrogen dioxide above75ᵗʰ percentile\n",
      "     12. FoT Nitrogen monoxide above75ᵗʰ percentile\n",
      "     13. FoT Ozone above75ᵗʰ percentile\n",
      "     14. FoT PM$_{2.5}$ above75ᵗʰ percentile\n",
      "     15. FoT Peroxyacetyl Nitrate above75ᵗʰ percentile\n",
      "     16. FoT Propane above75ᵗʰ percentile\n",
      "     17. FoT Sulphur dioxide above75ᵗʰ percentile\n",
      "     18. Isoprene\n",
      "     19. Land-sea mask\n",
      "     20. Leaf area index, high vegetation\n",
      "     21. Leaf area index, low vegetation\n",
      "     22. Mean sea level pressure\n",
      "     23. Organic matter AOD at 550 nm\n",
      "     24. Relative humidity\n",
      "     25. Sea salt AOD at 550 nm\n",
      "     26. Snow albedo\n",
      "     27. Snow depth\n",
      "     28. Sulphate AOD at 550 nm\n",
      "     29. Surface pressure\n",
      "     30. fips\n",
      "\n",
      "======================================================================\n",
      "TOTAL BREAKDOWN:\n",
      "  Identifiers: 3\n",
      "  Target: 1\n",
      "  Demographics: 9\n",
      "  Livestock: 8\n",
      "  Weather: 30\n",
      "  TOTAL: 51\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"REMAINING COLUMNS ({len(df_reduced.columns)})\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Define identifiers and target\n",
    "identifiers = ['County', 'State', 'Year']\n",
    "target = ['Mean Life Expectancy']\n",
    "\n",
    "# Define demographics variables (original list minus dropped ones)\n",
    "all_demographics = [\n",
    "    'Median Household Income',  # dropped\n",
    "    'Total Population',\n",
    "    'Gini Index',  # dropped\n",
    "    'Median Age',  # dropped\n",
    "    'Poverty Rate',\n",
    "    'Unemployment Rate',\n",
    "    'Disability Rate',\n",
    "    \"Bachelor's Degree or Higher (%)\",\n",
    "    \"High School Degree or Higher (%)\",  # dropped\n",
    "    'White Population (%)',  # dropped\n",
    "    'Hispanic Population (%)',\n",
    "    'Black Population (%)',\n",
    "    'Households with No Vehicle (%)',\n",
    "    'Rent Burden (+50% of HI)',  # dropped\n",
    "    'Single Mother Families (%)'\n",
    "]\n",
    "demographics_remaining = [col for col in all_demographics if col in df_reduced.columns]\n",
    "\n",
    "# Define livestock variables\n",
    "livestock = ['Buffalo', 'Cattle', 'Chicken', 'Duck', 'Goat', 'Horse', 'Pig', 'Sheep']\n",
    "livestock_remaining = [col for col in livestock if col in df_reduced.columns]\n",
    "\n",
    "# Weather variables are everything else\n",
    "known_cols = identifiers + target + demographics_remaining + livestock_remaining\n",
    "weather_remaining = [col for col in df_reduced.columns if col not in known_cols]\n",
    "\n",
    "# Display categorization\n",
    "print(\"\\n1. Identifiers (3):\")\n",
    "for col in identifiers:\n",
    "    if col in df_reduced.columns:\n",
    "        print(f\"      {col}\")\n",
    "\n",
    "print(\"\\n2. Target Variable (1):\")\n",
    "for col in target:\n",
    "    if col in df_reduced.columns:\n",
    "        print(f\"      {col}\")\n",
    "\n",
    "print(f\"\\n3. Demographics Variables ({len(demographics_remaining)}):\")\n",
    "for i, col in enumerate(demographics_remaining, 1):\n",
    "    print(f\"     {i}. {col}\")\n",
    "\n",
    "print(f\"\\n4. Livestock Variables ({len(livestock_remaining)}):\")\n",
    "for i, col in enumerate(livestock_remaining, 1):\n",
    "    print(f\"     {i}. {col}\")\n",
    "\n",
    "print(f\"\\n5. Weather Variables ({len(weather_remaining)}):\")\n",
    "for i, col in enumerate(sorted(weather_remaining), 1):\n",
    "    print(f\"     {i:2}. {col}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"TOTAL BREAKDOWN:\")\n",
    "print(f\"  Identifiers: {len([c for c in identifiers if c in df_reduced.columns])}\")\n",
    "print(f\"  Target: {len([c for c in target if c in df_reduced.columns])}\")\n",
    "print(f\"  Demographics: {len(demographics_remaining)}\")\n",
    "print(f\"  Livestock: {len(livestock_remaining)}\")\n",
    "print(f\"  Weather: {len(weather_remaining)}\")\n",
    "print(f\"  TOTAL: {df_reduced.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd32016",
   "metadata": {},
   "source": [
    "## 7. Format Weather Variable Names to Title Case\n",
    "\n",
    "### 7.1 Create Title Case Mapping\n",
    "\n",
    "Convert weather variable names to Title Case (capitalize first letters of words).\n",
    "Keep LaTeX notation, special characters, and units as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b82c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CREATING TITLE CASE MAPPING FOR WEATHER VARIABLES\n",
      "======================================================================\n",
      "\n",
      "Created Title Case mapping for 30 weather variables\n",
      "\n",
      "Sample conversions:\n",
      "   1. fips\n",
      "       Fips\n",
      "   2. Black carbon AOD at 550 nm\n",
      "       Black Carbon AOD At 550 Nm\n",
      "   3. Dust AOD at 550 nm\n",
      "       Dust AOD At 550 Nm\n",
      "   4. Land-sea mask\n",
      "       Land-sea Mask\n",
      "   5. Mean sea level pressure\n",
      "       Mean Sea Level Pressure\n",
      "   6. Organic matter AOD at 550 nm\n",
      "       Organic Matter AOD At 550 Nm\n",
      "   7. Sea salt AOD at 550 nm\n",
      "       Sea Salt AOD At 550 Nm\n",
      "   8. Sulphate AOD at 550 nm\n",
      "       Sulphate AOD At 550 Nm\n",
      "   9. Surface pressure\n",
      "       Surface Pressure\n",
      "  10. Isoprene\n",
      "       Isoprene\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CREATING TITLE CASE MAPPING FOR WEATHER VARIABLES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Function to convert to Title Case while preserving special characters\n",
    "def to_title_case_preserve_special(name):\n",
    "    \"\"\"\n",
    "    Convert variable name to Title Case while preserving:\n",
    "    - LaTeX notation: $_{2.5}$, $\\\\mathrm{^o F}$\n",
    "    - Special characters: µm, ᵗʰ\n",
    "    - Units and parentheses\n",
    "    \"\"\"\n",
    "    # Split by spaces and capitalize each word\n",
    "    words = name.split(' ')\n",
    "    titled_words = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Don't capitalize words that are all lowercase units or special notation\n",
    "        # Capitalize everything else\n",
    "        if word:  # Skip empty strings\n",
    "            # Capitalize first letter if it's a letter\n",
    "            if word[0].isalpha():\n",
    "                titled_words.append(word[0].upper() + word[1:])\n",
    "            else:\n",
    "                titled_words.append(word)\n",
    "    \n",
    "    return ' '.join(titled_words)\n",
    "\n",
    "# Create mapping for weather variables only\n",
    "weather_name_mapping = {}\n",
    "\n",
    "for col in weather_remaining:\n",
    "    # Convert to Title Case\n",
    "    new_name = to_title_case_preserve_special(col)\n",
    "    weather_name_mapping[col] = new_name\n",
    "\n",
    "print(f\"\\nCreated Title Case mapping for {len(weather_name_mapping)} weather variables\")\n",
    "print(\"\\nSample conversions:\")\n",
    "for i, (old, new) in enumerate(list(weather_name_mapping.items())[:10], 1):\n",
    "    print(f\"  {i:2}. {old}\")\n",
    "    print(f\"       {new}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985de315",
   "metadata": {},
   "source": [
    "### 7.2 Apply Title Case Formatting\n",
    "\n",
    "Rename weather columns to Title Case format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf54d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "APPLYING TITLE CASE FORMATTING\n",
      "======================================================================\n",
      "\n",
      " Renamed 30 weather variables to Title Case\n",
      "\n",
      "Note: Demographics variables already in correct format (no changes)\n",
      "      Livestock variables already in correct format (no changes)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"APPLYING TITLE CASE FORMATTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Apply renaming (only weather variables)\n",
    "df_reduced = df_reduced.rename(columns=weather_name_mapping)\n",
    "\n",
    "print(f\"\\n Renamed {len(weather_name_mapping)} weather variables to Title Case\")\n",
    "print(\"\\nNote: Demographics variables already in correct format (no changes)\")\n",
    "print(\"      Livestock variables already in correct format (no changes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591e0594",
   "metadata": {},
   "source": [
    "## 8. Verification\n",
    "\n",
    "### 8.1 Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "727bd93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATA QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "Missing values: 0\n",
      "   No missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df_reduced.isnull().sum()\n",
    "total_missing = missing_values.sum()\n",
    "\n",
    "print(f\"\\nMissing values: {total_missing}\")\n",
    "if total_missing > 0:\n",
    "    print(\"\\n Columns with missing values:\")\n",
    "    for col in df_reduced.columns:\n",
    "        if missing_values[col] > 0:\n",
    "            pct = (missing_values[col] / len(df_reduced)) * 100\n",
    "            print(f\"  {col}: {missing_values[col]:,} ({pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"   No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eabb37",
   "metadata": {},
   "source": [
    "### 8.2 Verify Year Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f238ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observations per year:\n",
      "  2012: 3,061 counties\n",
      "  2013: 3,061 counties\n",
      "  2014: 3,061 counties\n",
      "  2015: 3,061 counties\n",
      "  2016: 3,061 counties\n",
      "  2017: 3,061 counties\n",
      "  2018: 3,060 counties\n",
      "  2019: 3,061 counties\n",
      "\n",
      "Total counties per year: 3,061\n"
     ]
    }
   ],
   "source": [
    "# Check year distribution\n",
    "print(\"\\nObservations per year:\")\n",
    "year_counts = df_reduced['Year'].value_counts().sort_index()\n",
    "for year, count in year_counts.items():\n",
    "    print(f\"  {year}: {count:,} counties\")\n",
    "\n",
    "print(f\"\\nTotal counties per year: {year_counts.values[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a9aea",
   "metadata": {},
   "source": [
    "### 8.3 Verify Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e285b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target variable statistics (Mean Life Expectancy):\n",
      "  Count: 24,487\n",
      "  Min: 67.09 years\n",
      "  Max: 92.25 years\n",
      "  Mean: 77.35 years\n",
      "  Median: 77.47 years\n",
      "  Std Dev: 2.54 years\n"
     ]
    }
   ],
   "source": [
    "# Target variable statistics\n",
    "print(\"\\nTarget variable statistics (Mean Life Expectancy):\")\n",
    "print(f\"  Count: {df_reduced['Mean Life Expectancy'].count():,}\")\n",
    "print(f\"  Min: {df_reduced['Mean Life Expectancy'].min():.2f} years\")\n",
    "print(f\"  Max: {df_reduced['Mean Life Expectancy'].max():.2f} years\")\n",
    "print(f\"  Mean: {df_reduced['Mean Life Expectancy'].mean():.2f} years\")\n",
    "print(f\"  Median: {df_reduced['Mean Life Expectancy'].median():.2f} years\")\n",
    "print(f\"  Std Dev: {df_reduced['Mean Life Expectancy'].std():.2f} years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0c13b",
   "metadata": {},
   "source": [
    "### 8.4 Display Final Column List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d59032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL COLUMN LIST (51 columns)\n",
      "======================================================================\n",
      "\n",
      "All columns in final dataset:\n",
      "   1. County\n",
      "   2. State\n",
      "   3. Mean Life Expectancy\n",
      "   4. Poverty Rate\n",
      "   5. Bachelor's Degree or Higher (%)\n",
      "   6. Disability Rate\n",
      "   7. Total Population\n",
      "   8. Unemployment Rate\n",
      "   9. Year\n",
      "  10. Hispanic Population (%)\n",
      "  11. Black Population (%)\n",
      "  12. Households with No Vehicle (%)\n",
      "  13. Single Mother Families (%)\n",
      "  14. Fips\n",
      "  15. Black Carbon AOD At 550 Nm\n",
      "  16. Dust AOD At 550 Nm\n",
      "  17. Land-sea Mask\n",
      "  18. Mean Sea Level Pressure\n",
      "  19. Organic Matter AOD At 550 Nm\n",
      "  20. Sea Salt AOD At 550 Nm\n",
      "  21. Sulphate AOD At 550 Nm\n",
      "  22. Surface Pressure\n",
      "  23. Isoprene\n",
      "  24. Leaf Area Index, High Vegetation\n",
      "  25. Leaf Area Index, Low Vegetation\n",
      "  26. Snow Albedo\n",
      "  27. Snow Depth\n",
      "  28. Relative Humidity\n",
      "  29. 10m Wind Speed\n",
      "  30. FoT Carbonmonoxide Above75ᵗʰ Percentile\n",
      "  31. FoT Ethane Above75ᵗʰ Percentile\n",
      "  32. FoT Formaldehyde Above75ᵗʰ Percentile\n",
      "  33. FoT Hydroxyl Radical Above75ᵗʰ Percentile\n",
      "  34. FoT Isoprene Above75ᵗʰ Percentile\n",
      "  35. FoT Peroxyacetyl Nitrate Above75ᵗʰ Percentile\n",
      "  36. FoT Nitric Acid Above75ᵗʰ Percentile\n",
      "  37. FoT Nitrogen Dioxide Above75ᵗʰ Percentile\n",
      "  38. FoT Nitrogen Monoxide Above75ᵗʰ Percentile\n",
      "  39. FoT Ozone Above75ᵗʰ Percentile\n",
      "  40. FoT Hydrogen Peroxide Above75ᵗʰ Percentile\n",
      "  41. FoT PM$_{2.5}$ Above75ᵗʰ Percentile\n",
      "  42. FoT Propane Above75ᵗʰ Percentile\n",
      "  43. FoT Sulphur Dioxide Above75ᵗʰ Percentile\n",
      "  44. Buffalo\n",
      "  45. Cattle\n",
      "  46. Chicken\n",
      "  47. Duck\n",
      "  48. Goat\n",
      "  49. Horse\n",
      "  50. Pig\n",
      "  51. Sheep\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"FINAL COLUMN LIST ({len(df_reduced.columns)} columns)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nAll columns in final dataset:\")\n",
    "for i, col in enumerate(df_reduced.columns, 1):\n",
    "    print(f\"  {i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225c65f",
   "metadata": {},
   "source": [
    "### 8.5 Display Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a9f623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of final reduced dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>Mean Life Expectancy</th>\n",
       "      <th>Poverty Rate</th>\n",
       "      <th>Bachelor's Degree or Higher (%)</th>\n",
       "      <th>Disability Rate</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Unemployment Rate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Hispanic Population (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>FoT Propane Above75ᵗʰ Percentile</th>\n",
       "      <th>FoT Sulphur Dioxide Above75ᵗʰ Percentile</th>\n",
       "      <th>Buffalo</th>\n",
       "      <th>Cattle</th>\n",
       "      <th>Chicken</th>\n",
       "      <th>Duck</th>\n",
       "      <th>Goat</th>\n",
       "      <th>Horse</th>\n",
       "      <th>Pig</th>\n",
       "      <th>Sheep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autauga County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>75.729244</td>\n",
       "      <td>11.6</td>\n",
       "      <td>24.4</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54590.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.399707</td>\n",
       "      <td>...</td>\n",
       "      <td>24.795082</td>\n",
       "      <td>56.523224</td>\n",
       "      <td>104.304193</td>\n",
       "      <td>765.477347</td>\n",
       "      <td>1460.733157</td>\n",
       "      <td>6.200551</td>\n",
       "      <td>47.556840</td>\n",
       "      <td>54.780249</td>\n",
       "      <td>3.199114</td>\n",
       "      <td>13.548855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>77.927178</td>\n",
       "      <td>13.3</td>\n",
       "      <td>29.3</td>\n",
       "      <td>14.0</td>\n",
       "      <td>183226.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.319802</td>\n",
       "      <td>...</td>\n",
       "      <td>14.310109</td>\n",
       "      <td>30.327869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>356.486268</td>\n",
       "      <td>20.764893</td>\n",
       "      <td>2.339871</td>\n",
       "      <td>20.358615</td>\n",
       "      <td>74.033112</td>\n",
       "      <td>3.038270</td>\n",
       "      <td>4.505194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Barbour County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>75.726346</td>\n",
       "      <td>26.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>27469.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>4.969238</td>\n",
       "      <td>...</td>\n",
       "      <td>20.252732</td>\n",
       "      <td>11.475410</td>\n",
       "      <td>74.777062</td>\n",
       "      <td>595.600612</td>\n",
       "      <td>150608.306932</td>\n",
       "      <td>6.572719</td>\n",
       "      <td>11.807808</td>\n",
       "      <td>24.807758</td>\n",
       "      <td>8.248660</td>\n",
       "      <td>6.213882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bibb County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>73.854904</td>\n",
       "      <td>16.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>22769.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.840221</td>\n",
       "      <td>...</td>\n",
       "      <td>27.117486</td>\n",
       "      <td>59.187158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>288.782290</td>\n",
       "      <td>516.739571</td>\n",
       "      <td>3.657299</td>\n",
       "      <td>15.416166</td>\n",
       "      <td>42.510005</td>\n",
       "      <td>20.036976</td>\n",
       "      <td>2.450206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blount County</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>75.703162</td>\n",
       "      <td>14.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>57466.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.084781</td>\n",
       "      <td>...</td>\n",
       "      <td>32.411202</td>\n",
       "      <td>62.773224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1692.635794</td>\n",
       "      <td>549287.154544</td>\n",
       "      <td>16.943384</td>\n",
       "      <td>42.096943</td>\n",
       "      <td>228.072444</td>\n",
       "      <td>9.920152</td>\n",
       "      <td>22.714804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           County    State  Mean Life Expectancy  Poverty Rate  \\\n",
       "0  Autauga County  Alabama             75.729244          11.6   \n",
       "1  Baldwin County  Alabama             77.927178          13.3   \n",
       "2  Barbour County  Alabama             75.726346          26.1   \n",
       "3     Bibb County  Alabama             73.854904          16.5   \n",
       "4   Blount County  Alabama             75.703162          14.7   \n",
       "\n",
       "   Bachelor's Degree or Higher (%)  Disability Rate  Total Population  \\\n",
       "0                             24.4             15.0           54590.0   \n",
       "1                             29.3             14.0          183226.0   \n",
       "2                             13.0             20.5           27469.0   \n",
       "3                              8.2             16.2           22769.0   \n",
       "4                             12.0             17.3           57466.0   \n",
       "\n",
       "   Unemployment Rate  Year  Hispanic Population (%)  ...  \\\n",
       "0                8.6  2012                 2.399707  ...   \n",
       "1                8.5  2012                 4.319802  ...   \n",
       "2               13.5  2012                 4.969238  ...   \n",
       "3               10.5  2012                 1.840221  ...   \n",
       "4               10.0  2012                 8.084781  ...   \n",
       "\n",
       "   FoT Propane Above75ᵗʰ Percentile  FoT Sulphur Dioxide Above75ᵗʰ Percentile  \\\n",
       "0                         24.795082                                 56.523224   \n",
       "1                         14.310109                                 30.327869   \n",
       "2                         20.252732                                 11.475410   \n",
       "3                         27.117486                                 59.187158   \n",
       "4                         32.411202                                 62.773224   \n",
       "\n",
       "      Buffalo       Cattle        Chicken       Duck       Goat       Horse  \\\n",
       "0  104.304193   765.477347    1460.733157   6.200551  47.556840   54.780249   \n",
       "1    0.000000   356.486268      20.764893   2.339871  20.358615   74.033112   \n",
       "2   74.777062   595.600612  150608.306932   6.572719  11.807808   24.807758   \n",
       "3    0.000000   288.782290     516.739571   3.657299  15.416166   42.510005   \n",
       "4    0.000000  1692.635794  549287.154544  16.943384  42.096943  228.072444   \n",
       "\n",
       "         Pig      Sheep  \n",
       "0   3.199114  13.548855  \n",
       "1   3.038270   4.505194  \n",
       "2   8.248660   6.213882  \n",
       "3  20.036976   2.450206  \n",
       "4   9.920152  22.714804  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nSample of final reduced dataset:\")\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b7a7c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types:\n",
      "float64    47\n",
      "object      2\n",
      "int64       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display data types\n",
    "print(\"\\nData types:\")\n",
    "print(df_reduced.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce3c2c",
   "metadata": {},
   "source": [
    "## 9. Save Final Reduced Dataset\n",
    "\n",
    "Export the final reduced dataset with selected features only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a8c3fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL REDUCED DATASET SAVED\n",
      "======================================================================\n",
      " File: ../data_cleaned/combined_final/final_combined_all_variables_reduced.csv\n",
      "  - Shape: (24487, 51)\n",
      "  - Rows: 24,487\n",
      "  - Columns: 51\n",
      "  - File size: 18.66 MB\n"
     ]
    }
   ],
   "source": [
    "# Create output directory if needed\n",
    "output_dir = Path('../data_cleaned/combined_final')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save reduced dataset\n",
    "output_path = output_dir / 'final_combined_all_variables_reduced.csv'\n",
    "df_reduced.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FINAL REDUCED DATASET SAVED\")\n",
    "print(\"=\" * 70)\n",
    "print(f\" File: {output_path}\")\n",
    "print(f\"  - Shape: {df_reduced.shape}\")\n",
    "print(f\"  - Rows: {df_reduced.shape[0]:,}\")\n",
    "print(f\"  - Columns: {df_reduced.shape[1]}\")\n",
    "print(f\"  - File size: {output_path.stat().st_size / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f1b76",
   "metadata": {},
   "source": [
    "## 10. Summary Report\n",
    "\n",
    "Complete summary of feature reduction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08711664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE REDUCTION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "1. CHANGES MADE:\n",
      "    Dropped 80 redundant variables\n",
      "     - Demographics: 6 variables\n",
      "     - Irrelevant weather: 59 variables\n",
      "     - Redundant weather: 15 variables\n",
      "    Formatted 30 weather variables to Title Case\n",
      "    Kept all 8 livestock variables\n",
      "\n",
      "2. DATASET COMPARISON:\n",
      "   Original: 131 columns, 24,487 rows\n",
      "   Reduced:  51 columns, 24,487 rows\n",
      "   Reduction: 80 columns (61.1%)\n",
      "\n",
      "3. FINAL FEATURE BREAKDOWN:\n",
      "   - Identifiers: 3 (County, State, Year)\n",
      "   - Target: 1 (Mean Life Expectancy)\n",
      "   - Demographics: 9 variables\n",
      "   - Weather: 30 variables (Title Case formatted)\n",
      "   - Livestock: 8 variables\n",
      "   - TOTAL: 51 columns\n",
      "\n",
      "4. DATA QUALITY:\n",
      "    No missing values: True\n",
      "    Years covered: 2012 - 2019\n",
      "    Counties per year: ~3061\n",
      "    Target variable range: 67.09 - 92.25 years\n",
      "\n",
      "5. OUTPUT:\n",
      "    Saved to: ../data_cleaned/combined_final/final_combined_all_variables_reduced.csv\n",
      "    File size: 18.66 MB\n",
      "\n",
      "======================================================================\n",
      " FEATURE REDUCTION COMPLETE\n",
      " Dataset ready for machine learning modeling (notebooks 09+)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FEATURE REDUCTION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. CHANGES MADE:\")\n",
    "print(f\"    Dropped {cols_dropped} redundant variables\")\n",
    "print(f\"     - Demographics: 6 variables\")\n",
    "print(f\"     - Irrelevant weather: {len([c for c in irrelevant_weather if c in df.columns])} variables\")\n",
    "print(f\"     - Redundant weather: {len([c for c in redundant_weather if c in df.columns])} variables\")\n",
    "print(f\"    Formatted {len(weather_name_mapping)} weather variables to Title Case\")\n",
    "print(f\"    Kept all {len(livestock_remaining)} livestock variables\")\n",
    "\n",
    "print(\"\\n2. DATASET COMPARISON:\")\n",
    "print(f\"   Original: {original_cols} columns, {original_rows:,} rows\")\n",
    "print(f\"   Reduced:  {reduced_cols} columns, {reduced_rows:,} rows\")\n",
    "print(f\"   Reduction: {cols_dropped} columns ({(cols_dropped/original_cols)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n3. FINAL FEATURE BREAKDOWN:\")\n",
    "print(f\"   - Identifiers: {len([c for c in identifiers if c in df_reduced.columns])} (County, State, Year)\")\n",
    "print(f\"   - Target: {len([c for c in target if c in df_reduced.columns])} (Mean Life Expectancy)\")\n",
    "print(f\"   - Demographics: {len(demographics_remaining)} variables\")\n",
    "print(f\"   - Weather: {len(weather_remaining)} variables (Title Case formatted)\")\n",
    "print(f\"   - Livestock: {len(livestock_remaining)} variables\")\n",
    "print(f\"   - TOTAL: {df_reduced.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n4. DATA QUALITY:\")\n",
    "print(f\"    No missing values: {total_missing == 0}\")\n",
    "print(f\"    Years covered: {df_reduced['Year'].min()} - {df_reduced['Year'].max()}\")\n",
    "print(f\"    Counties per year: ~{df_reduced.groupby('Year').size().mean():.0f}\")\n",
    "print(f\"    Target variable range: {df_reduced['Mean Life Expectancy'].min():.2f} - {df_reduced['Mean Life Expectancy'].max():.2f} years\")\n",
    "\n",
    "print(\"\\n5. OUTPUT:\")\n",
    "print(f\"    Saved to: {output_path}\")\n",
    "print(f\"    File size: {output_path.stat().st_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" FEATURE REDUCTION COMPLETE\")\n",
    "print(\" Dataset ready for machine learning modeling (notebooks 09+)\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
